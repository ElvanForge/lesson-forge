package main

import (
	"bytes"
	"context"
	"encoding/json"
	"errors"
	"fmt"
	"net/http"
	"os"
	"time"
)

type AIProvider interface {
	GenerateContent(ctx context.Context, prompt string) (string, error)
}

type GeminiProvider struct {
	APIKey string
}

func (g *GeminiProvider) GenerateContent(ctx context.Context, prompt string) (string, error) {
	url := fmt.Sprintf("https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash-lite-preview-02-05:generateContent?key=%s", g.APIKey)

	payload := map[string]interface{}{
		"contents": []map[string]interface{}{
			{
				"parts": []map[string]interface{}{
					{"text": prompt},
				},
			},
		},
	}

	jsonData, _ := json.Marshal(payload)
	req, _ := http.NewRequestWithContext(ctx, "POST", url, bytes.NewBuffer(jsonData))
	req.Header.Set("Content-Type", "application/json")

	resp, err := http.DefaultClient.Do(req)
	if err != nil {
		return "", err
	}
	defer resp.Body.Close()

	if resp.StatusCode != http.StatusOK {
		return "", fmt.Errorf("gemini api error: %d", resp.StatusCode)
	}

	var result struct {
		Candidates []struct {
			Content struct {
				Parts []struct {
					Text string `json:"text"`
				} `json:"parts"`
			} `json:"content"`
		} `json:"candidates"`
	}

	if err := json.NewDecoder(resp.Body).Decode(&result); err != nil {
		return "", err
	}

	if len(result.Candidates) == 0 || len(result.Candidates[0].Content.Parts) == 0 {
		return "", errors.New("no content generated by gemini")
	}

	return result.Candidates[0].Content.Parts[0].Text, nil
}

type DeepSeekProvider struct {
	APIKey string
}

func (d *DeepSeekProvider) GenerateContent(ctx context.Context, prompt string) (string, error) {
	url := "https://api.deepseek.com/v1/chat/completions"

	payload := map[string]interface{}{
		"model": "deepseek-chat",
		"messages": []map[string]interface{}{
			{"role": "user", "content": prompt},
		},
	}

	jsonData, _ := json.Marshal(payload)
	req, _ := http.NewRequestWithContext(ctx, "POST", url, bytes.NewBuffer(jsonData))
	req.Header.Set("Content-Type", "application/json")
	req.Header.Set("Authorization", "Bearer "+d.APIKey)

	resp, err := http.DefaultClient.Do(req)
	if err != nil {
		return "", err
	}
	defer resp.Body.Close()

	if resp.StatusCode != http.StatusOK {
		return "", fmt.Errorf("deepseek api error: %d", resp.StatusCode)
	}

	var result struct {
		Choices []struct {
			Message struct {
				Content string `json:"content"`
			} `json:"message"`
		} `json:"choices"`
	}

	if err := json.NewDecoder(resp.Body).Decode(&result); err != nil {
		return "", err
	}

	if len(result.Choices) == 0 {
		return "", errors.New("no content generated by deepseek")
	}

	return result.Choices[0].Message.Content, nil
}

type MockProvider struct{}

func (m *MockProvider) GenerateContent(ctx context.Context, prompt string) (string, error) {
	// Simulate some delay
	select {
	case <-time.After(500 * time.Millisecond):
	case <-ctx.Done():
		return "", ctx.Err()
	}

	return `# Mock Generation for: ` + prompt + `

## Section 1: Overview
This is a mock response generated to save API costs during testing.
- Key Point A
- Key Point B

## Section 2: Details
The system correctly tracked your credits and validated your session.
- Image Description: A teacher using an AI tool in a modern classroom.
- Image Description: A data dashboard showing perfect security metrics.

## Conclusion
Everything is working as expected!`, nil
}

func GetAIProvider() AIProvider {
	if os.Getenv("MOCK_AI") == "true" {
		return &MockProvider{}
	}
	if os.Getenv("LOCATION") == "CN" {
		return &DeepSeekProvider{APIKey: os.Getenv("DEEPSEEK_KEY")}
	}
	return &GeminiProvider{APIKey: os.Getenv("GEMINI_KEY")}
}
